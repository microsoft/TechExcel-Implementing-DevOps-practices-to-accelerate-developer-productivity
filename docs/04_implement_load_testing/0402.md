---
title: '2. Run a load test from GitHub Actions'
layout: default
nav_order: 2
parent: 'Exercise 04: Implement load testing and secure practices'
---

# Task 02 - Run a load test from GitHub Actions (75 minutes)

## Introduction

In this task, you will use a load testing script in Apache JMeter which should hit each application endpoint. This script will implement the load testing strategy you created in the previous task. Your scripts should help you get a baseline for how the application can handle typical user loads.

Azure Load Testing is based on Apache JMeter - a popular open source load testing tool. This means you can reuse existing JMeter scripts or create new scripts by using the JMeter GUI.

To demonstrate this, you will then create a Load Testing service in Azure and use the load testing scripts you created to run baseline tests.

Baselines help to determine the current efficiency state of your application and its supporting infrastructure. They can provide good insights for improvements and determine if the application is meeting business goals. Baselines can exist for an application in any state of maturity, so no matter when you establish the baseline, you can measure performance against that baseline during continued development. When code or infrastructure changes, you can actively measure the performance impact of that change.

After creating a baseline, you will integrate Azure Load Testing into your CI/CD pipeline as part of a GitHub Action workflow.

## Description

Now that you have demonstrated your load testing plan for the Team Messaging System to the development team at Munson's Pickles and Preserves, it is time to put it into action.

1. Open the [LoadTestScript.jmx](../../Solution/Exercise-04/Task-2/LoadTestScript.jmx). Note that this file is in XML format.
2. Create an environment variable on your Dev Box called `webapp`. Its value should be the URL for your dev site, in the format `{yourprefix}-dev.azurewebsites.net` with no `https://` or trailing slashes. The following command line operation provides an example of how to create the environment variable in the Windows command prompt:

    `setx webapp {yourprefix}-dev.azurewebsites.net`

3. Using the JMeter GUI, open the LoadTestScript.jmx file. Review each of the steps in the GUI and see how we are testing the website.
4. Execute the load test using the JMeter GUI against your endpoints and use the Azure portal to confirm the App Service is getting the traffic.
5. Create an Azure Load Testing resource.
6. Create a load test in the Load Testing service that accepts the website URL as an environment variable called `webapp` and passes that value to your load testing script.
7. Run your load test multiple times using a typical user load and establish a performance baseline.
8. Review the test results, identify the bottlenecks (CPU, memory, resource limits), and compile a list of insights.
9. Discuss with the rest of your group where you may be able to leverage the baseline data you have gathered.
10. Use the Azure Load Testing GitHub Action to execute your load test with a manual trigger.
11. Intentionally set the pass/fail rules in your test configuration to a value that would cause the test to fail during the workflow.
12. On load test failure, automatically create a GitHub Issue.

## Success Criteria

- Verify that you have a load testing script in .jmx format that targets each application endpoint.
- Verify that your load test works in JMeter and you are able to see the load in your sample application.
- Show your load tests running in Azure Load Testing service, as well as your performance baseline.
- Verify that you can run the same load test and change parameters to hit different environments.
- Demonstrate that you can execute your load test on a manual GitHub Actions workflow trigger.
- Demonstrate that, when the load test fails due to it not meeting a performance target, your workflow automatically creates a GitHub Issue.

## Learning Resources

- [A video demonstration of how to create a JMeter script file](../../Solution/Exercise-04/Task-2/Exercise%204%20Task%202%20Video%20Demonstration.mp4)
- [Apache JMeter Getting Started](https://jmeter.apache.org/usermanual/get-started.html) - This requires Java 8+ to be installed
- [Apache JMeter Docs](https://jmeter.apache.org/index.html)
- [Create Test Plan from Template](https://jmeter.apache.org/usermanual/get-started.html#template)
- [JMeter best practices](https://jmeter.apache.org/usermanual/best-practices.html)
- [Custom Plugins for Apache JMeter](https://jmeter-plugins.org/)
- [Establish Baselines](https://docs.microsoft.com/azure/architecture/framework/scalability/performance-test#establish-baselines)
- [Create configurable load tests with secrets and environment variables](https://docs.microsoft.com/azure/load-testing/how-to-parameterize-load-tests)
- [Load Testing documentation](https://docs.microsoft.com/azure/load-testing/)
- [Video: JMeter Test Script Recorder](https://www.youtube.com/watch?v=voYj16cETAM)
- [JMeter + POST + anti-forgery token](https://stackoverflow.com/questions/53034969/jmeter-post-anti-forgery-token)

## Solution

<details>
<summary>Expand this section to view the solution</summary>

- A sample JMeter script is in [the solutions folder](../Solution/Exercise-04/Task-2/LoadTestScript.jmx). This covers steps 1-4.
  - Before creating or running the script, create an environment variable called `webapp` on the Dev Box. Its value should be the URL for your site, in the format `{yourprefix}-dev.azurewebsites.net` with no `https://` or trailing slashes. The following command line operation provides an example of how to create the environment variable in the Windows command prompt:

    `setx webapp {yourprefix}-dev.azurewebsites.net`

  - The JMeter test plan includes the following components. If you wish to re-create the file, you can do so by adding the following items in order:
    - Thread Group to perform testing (right-click on the Test Plan and select Add -> Threads to add the Thread Group). The thread group should include 30 threads and 30 loops.
      - HTTP Request Defaults (right-click on the Thread Group and choose Add -> Config Element). Set the protocol to https and the server name or IP to your deployed website. The included script sets the server name to a variable called `${site}`, which uses the environment variable on the PC called `webapp`.
      - Recording Controller (Add -> Logic Controller)
    - HTTP(S) Test Script recorder (Add -> Non-Test Elements)
      - On the test script recorder, the default port is 8888.
    - View Results in Table (Add -> Listener). This allows you to view test results in a table and get a quick idea of how the website is performing during a test.
    - View Results Tree (Add -> Listener). This allows you to view individual test results and diagnose potential issues such as 400 Bad Request.
  - The following steps allow you to perform a test recording.
    - Start the recorder by selecting the Start button on the HTTP(S) Test Script Recorder element. The first time you do this, JMeter will generate a temporary root certificate in `C:\apache-jmeter-5.6.2\bin\` (or wherever you installed JMeter). Stop the recording by selecting the Stop button.
    - Although you can use any browser for testing, the Firefox browser is recommended for this because you can set a manual proxy and do not need to create a Windows-wide proxy like you would for Chrome or Edge. You can set a proxy in Firefox by navigating to the options menu and then choosing Settings. Then, search for "proxy" in the settings search bar and select the Settings button for network settings. When running the test script, use a manual proxy configured to localhost on port 8888, and use it for HTTP as well as HTTPS. After setting the proxy, search for "certificate" in the settings search bar and then select the View Certificates button. From there, navigate to Authorities and choose the Import button. Inside `C:\apache-jmeter-5.6.2\bin\` (or wherever you installed JMeter), select the `ApacheJMeterTemporaryRootCA.crt` certificate and import it into Firefox.
    - After enabling the proxy and importing the certificate, you should be able to return to JMeter and restart the test recording.
    - During the recording, you should capture activities like viewing the page, adding a message, deleting a message, and analyzing messages.
  - After stopping a test recording, you will have a series of test actions. You will need to capture the request verification token from the first call in order to ensure that you have a proper CSRF token for all subsequent calls.
    - Right-click on the first recorded message in the Recording Controller element and select Add -> Post Processors -> CSS Selector Extractor.
    - In the CSS Selector Extractor, set the following attributes:
      - Name of created variable = `token`
      - CSS Selector expression = `input[name=__RequestVerificationToken]`
      - Attribute = `value`
    - For each subsequent call, replace the Value of the "__RequestVerificationToken" parameter with `${token}`. You will only see this parameter on POST requests, not GET requests.
- The following instructions cover steps 5-9.
  - Create Azure Load Testing resource
    - Search for the "Azure Load Testing" resource on the top search bar and select the resource.
    - On the top left hand corner select **Create**
    - Select the Resource Group that was created by the sample app or create your own.  The resources must be in the same location.
    - Enter a unique name for the resource.
    - Ensure the location matches the location that your application is deployed to.
    - Select **Review + create**
    - Review your configurations and then select **Create**
  - Create Load Test
    - Go into your new resource.  You may see a warning on the top depending on your current access describing the access levels required.  If so, add yourself as one of the roles such as "Load Testing Owner" or "Load Testing Contributor" as you will not be able to proceed otherwise.
    - Select **Create**
    - Fill out the name of the test and a description of the test.
    - Go to the **Test Plan** tab and select the JMeter script you have locally and then select **Upload**
    - Under the **Parameters** tab, enter "webapp" for the name of the environment variable, followed by the URL for your sample app in the "Value" section **without** `https://`.
    - Under the **Monitoring** tab, select **Add/Modify** and select the App Service for the sample app followed by **Apply** in order to monitor the app during testing.
    - Select **Review + create**
    - Review the settings and select **Create**
  - Run the load test
    - In your Azure Load Test service, select **Tests** from the left hand side
    - Select the test that you created from the list
    - At the top of the screen select **Run**
    - A summary page should appear.  Add that this run is the baseline in the description.  Select **Run**
  - Set Pass/Fail Criteria
    - Go back to your load test and select **Configure** followed by **Test**
    - Go to the **Test Criteria** Tab.
    - Enter in your test criteria such as failure rate under x %
- The following high-level notes cover steps 10-12. In addition, [a GitHub Actions workflow YAML file](../../Solution/Exercise-04/Task-2/LoadTest.yml) and [an Azure Load Test configuration file](../../Solution/Exercise-04/Task-2/LoadTestConfig.yaml) are available in the solutions folder.
  - The file `LoadTest.yml` should go into `.github/workflows`. The files `LoadTestConfig.yaml` and `LoadTestScript.jmx` should go into the root of the repository. The file `load_test_report.md` should go into a new folder called `.github/ISSUE_TEMPLATE`. Make sure to update `load_test_report.md` to set the assignee to your username.
  - This is a sample action that will run a load test.  The default action will either create or run the existing load test. However, GitHub Actions will automatically lower-case the value of the "TestName" parameter inside `LoadTestConfig.yaml`. Because the UI allows upper or lowercase letters, this can lead to duplicate tests existing in the Azure Load Test workspace.
  - You can use the baseline from their first run in challenge 3 to determine pass/fail criteria.

</details>
